{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function for training data: 935471510070.5972\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import lsqr\n",
    "\n",
    "# Load the data\n",
    "user_clip_train = pd.read_csv('user_clip.csv').dropna()\n",
    "\n",
    "# Calculate the average rating\n",
    "r_avg = user_clip_train['weight'].mean()\n",
    "\n",
    "# Create mappings for user_id and clip_id to indices\n",
    "user_ids = pd.Categorical(user_clip_train['user_id'])\n",
    "user_map = {user: i for i, user in enumerate(user_ids.categories)}\n",
    "clip_ids = pd.Categorical(user_clip_train['clip_id'])\n",
    "clip_map = {clip: i for i, clip in enumerate(clip_ids.categories)}\n",
    "\n",
    "# Extract user and clip indices\n",
    "user_indices = user_clip_train['user_id'].map(user_map).values\n",
    "clip_indices = user_clip_train['clip_id'].map(clip_map).values\n",
    "\n",
    "# Create the sparse design matrix\n",
    "num_ratings = len(user_clip_train)\n",
    "num_users = len(user_ids.categories)\n",
    "num_clips = len(clip_ids.categories)\n",
    "\n",
    "# Build the sparse matrix using user and clip indices\n",
    "row_indices = np.arange(num_ratings)\n",
    "col_indices_users = user_indices\n",
    "col_indices_clips = clip_indices + num_users\n",
    "\n",
    "data_users = np.ones(num_ratings)\n",
    "data_clips = np.ones(num_ratings)\n",
    "\n",
    "row_indices_combined = np.concatenate([row_indices, row_indices])\n",
    "col_indices_combined = np.concatenate([col_indices_users, col_indices_clips])\n",
    "data_combined = np.concatenate([data_users, data_clips])\n",
    "\n",
    "# Create the sparse matrix\n",
    "A = csr_matrix((data_combined, (row_indices_combined, col_indices_combined)), shape=(num_ratings, num_users + num_clips))\n",
    "\n",
    "# Create the target vector by subtracting the average weight from the actual weights\n",
    "y = np.array(user_clip_train['weight'] - r_avg)\n",
    "\n",
    "# Solve the linear system to find the biases for users and clips using the least-squares method\n",
    "b = lsqr(A, y)[0]\n",
    "\n",
    "# Store the biases in a dictionary\n",
    "bias_dict = pd.Series(b, index=[f\"user_{user_id}\" for user_id in user_ids.categories] + [f\"clip_{clip_id}\" for clip_id in clip_ids.categories])\n",
    "\n",
    "# Function to predict rank for a single row\n",
    "def predict_viewtime(row):\n",
    "    user_bias = bias_dict.get(f\"user_{row['user_id']}\", 0)\n",
    "    clip_bias = bias_dict.get(f\"clip_{row['clip_id']}\", 0)\n",
    "    return r_avg + user_bias + clip_bias\n",
    "\n",
    "# Load the test data\n",
    "test_df = pd.read_csv('test.csv').dropna()\n",
    "\n",
    "# Predict weights for the test dataset\n",
    "test_df['weight_pred'] = test_df.apply(predict_viewtime, axis=1)\n",
    "\n",
    "# Ensure no negative predictions\n",
    "test_df['weight_pred'] = test_df['weight_pred'].clip(lower=0)\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "test_df[['user_id', 'clip_id', 'weight_pred']].to_csv('319044434_314779166_task1.csv', index=False)\n",
    "\n",
    "# Function to calculate the objective function (error + regularization)\n",
    "def f1(df, user_bias, clip_bias):\n",
    "    error = ((df['prediction'] - df['weight']) ** 2).sum()\n",
    "    regularization = 0.1 * ((user_bias ** 2).sum() + (clip_bias ** 2).sum())\n",
    "    return error + regularization\n",
    "\n",
    "# Calculate predictions for training data\n",
    "user_clip_train['prediction'] = user_clip_train.apply(predict_viewtime, axis=1)\n",
    "\n",
    "# Extract user and clip biases from the bias series\n",
    "user_bias_values = bias_dict.iloc[:num_users].values\n",
    "clip_bias_values = bias_dict.iloc[num_users:].values\n",
    "\n",
    "# Calculate the F1 score for training data\n",
    "f1_score = f1(user_clip_train, user_bias_values, clip_bias_values)\n",
    "print(f'Loss function for training data: {f1_score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "user_clip = pd.read_csv('user_clip.csv').dropna()\n",
    "user_clip_matrix = user_clip.pivot(index='user_id', columns='clip_id', values='weight').fillna(0)\n",
    "user_ids = user_clip_matrix.index\n",
    "clip_ids = user_clip_matrix.columns\n",
    "\n",
    "user_clip_matrix = csr_matrix(user_clip_matrix.values)\n",
    "U, Σ, V_T = svds(user_clip_matrix, k=20)\n",
    "predicted_user_clip_matrix = U @ np.diag(Σ) @ V_T\n",
    "predicted_user_clip_matrix = pd.DataFrame(predicted_user_clip_matrix, columns=clip_ids, index=user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(user_id_test, clip_id_test):\n",
    "    if user_id_test in predicted_user_clip_matrix.index and clip_id_test in predicted_user_clip_matrix.columns:\n",
    "        return predicted_user_clip_matrix.loc[user_id_test, clip_id_test]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "test_df = pd.read_csv('test.csv').filter(['user_id', 'clip_id']).dropna()\n",
    "test_df['weight'] = test_df.apply(lambda row: predict(row['user_id'], row['clip_id']) ,axis=1)\n",
    "test_df.to_csv('319044434_314779166_task2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_user_clip = predicted_user_clip_matrix.reset_index().melt(id_vars='user_id', var_name='clip_id', value_name='weight')\n",
    "predicted_user_clip = predicted_user_clip.rename(columns={'weight': 'prediction'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229268390659.79825\n"
     ]
    }
   ],
   "source": [
    "def f2(weights, predictions):\n",
    "    merged_df = weights.merge(predictions, on=['user_id', 'clip_id'])\n",
    "    sse = ((merged_df['weight'] - merged_df['prediction']) ** 2).sum()\n",
    "    return sse\n",
    "\n",
    "print(f2(user_clip, predicted_user_clip))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
