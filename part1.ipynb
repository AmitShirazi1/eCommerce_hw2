{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "user_clip = pd.read_csv('user_clip.csv').dropna()\n",
    "r_avg = user_clip['weight'].mean()\n",
    "users_bias = user_clip.groupby('user_id')['weight'].mean() - r_avg\n",
    "clips_bias = user_clip.groupby('clip_id')['weight'].mean() - r_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv').filter(['user_id', 'clip_id']).dropna()\n",
    "users_bias = users_bias.reset_index().rename(columns={'index': 'user_id', 'weight': 'user_bias'})\n",
    "clips_bias = clips_bias.reset_index().rename(columns={'index': 'clip_id', 'weight': 'clip_bias'})\n",
    "test_df = test_df.merge(users_bias, on=['user_id'], how='left')\n",
    "test_df = test_df.merge(clips_bias, on=['clip_id'], how='left')\n",
    "test_df['prediction'] = r_avg + test_df['user_bias'] + test_df['clip_bias']\n",
    "test_df.filter(['user_id', 'clip_id', 'prediction']).rename(columns={'prediction': 'weight'}).to_csv('319044434_314779166_task1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_clip = user_clip.merge(users_bias, on=['user_id'], how='left')\n",
    "user_clip = user_clip.merge(clips_bias, on=['clip_id'], how='left')\n",
    "user_clip['prediction'] = r_avg + user_clip['user_bias'] + user_clip['clip_bias']\n",
    "user_clip['prediction'] = user_clip['prediction'].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "965092157923.618\n"
     ]
    }
   ],
   "source": [
    "def f1(df):\n",
    "    error = ((df['prediction'] - df['weight']) ** 2).sum()\n",
    "    regularization = 0.1 * ((df['user_bias'] ** 2).sum() + (df['clip_bias'] ** 2).sum())\n",
    "    return error + regularization\n",
    "\n",
    "print(f1(user_clip))\n",
    "\n",
    "# TODO: Question for the metargel:\n",
    "# 1. What do we do with predictions below 0 (both in train and test)?\n",
    "# 2. What do we do with missing values (currently - we drop them)?\n",
    "# 3. Is f1 and f2 on the test or train?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "user_clip = pd.read_csv('user_clip.csv').dropna()\n",
    "user_clip_matrix = user_clip.pivot(index='user_id', columns='clip_id', values='weight').fillna(0)\n",
    "user_ids = user_clip_matrix.index\n",
    "clip_ids = user_clip_matrix.columns\n",
    "\n",
    "user_clip_matrix = csr_matrix(user_clip_matrix.values)\n",
    "U, Σ, V_T = svds(user_clip_matrix, k=20)\n",
    "predicted_user_clip_matrix = U @ np.diag(Σ) @ V_T\n",
    "predicted_user_clip_matrix = pd.DataFrame(predicted_user_clip_matrix, columns=clip_ids, index=user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(user_id_test, clip_id_test):\n",
    "    if user_id_test in predicted_user_clip_matrix.index and clip_id_test in predicted_user_clip_matrix.columns:\n",
    "        return predicted_user_clip_matrix.loc[user_id_test, clip_id_test]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "test_df = pd.read_csv('test.csv').filter(['user_id', 'clip_id']).dropna()\n",
    "test_df['weight'] = test_df.apply(lambda row: predict(row['user_id'], row['clip_id']) ,axis=1)\n",
    "test_df.to_csv('319044434_314779166_task2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_user_clip = predicted_user_clip_matrix.reset_index().melt(id_vars='user_id', var_name='clip_id', value_name='weight')\n",
    "predicted_user_clip = predicted_user_clip.rename(columns={'weight': 'prediction'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id clip_id  weight  prediction\n",
      "0          145   64135     131   31.292638\n",
      "1          145   71619     445    1.012568\n",
      "2          145   76710      74    0.216014\n",
      "3          145   77532     157    0.231579\n",
      "4          145   98678      67    0.065738\n",
      "...        ...     ...     ...         ...\n",
      "80597   999659  844418      36    0.010661\n",
      "80598   999975   43850      74    0.020930\n",
      "80599   999975  249959      82    0.004242\n",
      "80600   999975  500176      98    0.004284\n",
      "80601   999975  627211      73    0.003335\n",
      "\n",
      "[80602 rows x 4 columns]\n",
      "229268390659.79822\n"
     ]
    }
   ],
   "source": [
    "def f2(weights, predictions):\n",
    "    merged_df = weights.merge(predictions, on=['user_id', 'clip_id'])\n",
    "    sse = ((merged_df['weight'] - merged_df['prediction']) ** 2).sum()\n",
    "    return sse\n",
    "\n",
    "print(f2(user_clip, predicted_user_clip))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
